





# For Dataset
import pandas as pd
import numpy as np

# For visualization
import seaborn as sns
import matplotlib.pyplot as plt

# Others
import string
import csv
import json





! ls *.csv








df1 = pd.read_csv('bom.movie_gross.csv')
df1.head(3)





# df1.head(3)
df2 = pd.read_csv('name.basics.csv')
df2.head(3)





df3 = pd.read_csv('title.akas.csv')
df3.head(3)





df4 = pd.read_csv('title.basics.csv')
df4.head(3)


df4.rename(columns = {'primary_title':'title'}, 
           inplace = True)
df4.head(3)





df5 = pd.read_csv('title.crew.csv')
df5.head(3)





df6 = pd.read_csv('title.principals.csv')
df6.head(3)





df7 = pd.read_csv('title.ratings.csv')
df7.head(3)





df8 = pd.read_csv('tmdb.movies.csv', 
                  index_col = 0)
df8.head(1)





df9 = pd.read_csv('tn.movie_budgets.csv')
df9.head(1)





df9.rename(columns = {'movie':'title'}, 
           inplace = True)

# Check whether the change has been made
if 'title' in df9.columns: print('Yes, `Movie` has been changed to `title`.')








def column_check(dat1, dat2):
    """
    This function checks to see whether there are columns
    in common. 

    Function counterchecks whether any column in `dat1` has any 
    of its columns in `dat2` columns.
    
    """
    for i in dat1.columns:
        if i in dat2.columns:
            print('Yes, there is a column in common:', i)
        
    else:
        # print('\nNo, Sadly there is no columns are similar.')
        print('\nThe End!')





column_check(df1, df2)








column_check(df1, df3)


df_13 = df1.merge(df3, 
                  on = 'title', 
                  how = 'outer',  
                  suffixes=('_fr1', '_fr3')
                 )
df_13.head(3)





column_check(df_13, df4)


df_134 = df_13.merge(df4, 
                  on = 'title', 
                  how = 'outer',  
                  suffixes=('_fr13', '_fr4')
                 )

df_134.head(3)





column_check(df_134, df5)


df_1345 = df_134.merge(df5, 
                  on = 'tconst', 
                  how = 'outer',  
                  suffixes = ('_fr134', '_fr5')
                 )

df_1345.head(3)





column_check(df_1345, df6)


df_13456 = df_1345.merge(df6, 
                  on = 'tconst', 
                  how = 'outer',  
                  suffixes = ('_fr1345', '_fr6')
                 )

df_13456.head(3)


## `Table 13456` and `Table 7`


column_check(df_13456, df7)


df_134567 = df_13456.merge(df7, 
                  on = 'tconst', 
                  how = 'outer',  
                  suffixes = ('_fr13456', '_fr7')
                 )
df_134567.head(3)





column_check(df_134567, df8)


df_1345678 = df_134567.merge(df8,
                  on = 'title', 
                  how = 'outer',  
                  suffixes=('_fr134567', '_fr8')
                 )

df_1345678.head(3)





column_check(df_1345678, df9)


df_13456789 = df_1345678.merge(df9,
                  on = 'title', 
                  how = 'outer',  
                  suffixes = ('_fr1345678', '_fr9')
                 )

df_13456789.head(3)





column_check(df_13456789, df2)


df_1to9 = df_13456789.merge(df2,
                  on = 'nconst', 
                  how = 'outer',  
                  suffixes = ('_fr1345678', '_fr9')
                 )

df_1to9.head(3)





len(df_1to9.columns)


df_1to9.columns


## Rearranging the columns
columns = [
    # Film Attributes
    'title_id', 'studio', 'language', 
    'title', 'original_title_fr8',
    'is_original_title',  'original_title_fr134567',
    'attributes', 'genres', 'genre_ids', 'characters',
    'runtime_minutes', 'category', 'types',
    
    # Timelines and Region
    'year', 'start_year', 'region', 'original_language', 
    'release_date_fr1345678', 'release_date_fr9', 
    
    # Professionals
    'primary_name', 'birth_year', 'death_year',
    'primary_profession', 'known_for_titles',
    'directors', 'writers', 'tconst', 'nconst', 'job',
    
    # Financials
    'production_budget', 'domestic_gross_fr1345678', 
    'domestic_gross_fr9', 'foreign_gross', 'worldwide_gross', 
    
    # Popularity Scores
    'averagerating', 'numvotes',  
    'vote_average', 'vote_count',
    'popularity',
    
    # Unknowns
    'ordering_fr1345', 'ordering_fr6', 'id_fr9',
    'id_fr1345678'
]


df = df_1to9[columns]
df.head(2)





# Checking the none-empty rows along `title_id` columns
df.loc[df.title_id.notna()]


df.info()


# none empty `title_id`
2349428 - 2209381


# Checking the none-empty rows along `title` columns
df.loc[df.title.notna()]


# none empty `title`
2349428 - 2347064 


print(df.shape)

# Drop the empty rows in either `title` or `title_id`
df.dropna(subset = ['title', 'title_id'],
          inplace = True)

# df.dropna(df.title_id.isnull(), 
#           inplace = True)

print(df.shape)


# number of removed rows
2349428 - 2209375





df.head(3)


## Rearranging the unknown columns
columns = [
    # Film Attributes
    'title_id', 'studio', 'language', 
    'title', 'original_title_fr8',
    'is_original_title',  'original_title_fr134567',
    'attributes', 'genres', 'genre_ids', 'characters',
    'runtime_minutes', 'types',
    
    # Timelines and Region
    'year', 'start_year', 'region', 'original_language', 
    'release_date_fr1345678', 'release_date_fr9', 
    
    # Professionals
    'primary_name', 'category', 'birth_year', 'death_year',
    'primary_profession', 'known_for_titles',
    'directors', 'writers', 'tconst', 'nconst', 'job',
    
    # Financials
    'production_budget', 'domestic_gross_fr1345678', 
    'domestic_gross_fr9', 'foreign_gross', 'worldwide_gross', 
    
    # Popularity Scores
    'averagerating', 'numvotes',  
    'vote_average', 'vote_count',
    'popularity'
]


# First remove unknown columns
df = df[columns]
df.info()





# First focusing on the `Film Attributes`
Film_Attributes = [
    'title_id', 'studio', 'language', 
    'title', 'original_title_fr8',
    'is_original_title',  'original_title_fr134567',
    'attributes', 'genres', 'genre_ids', 'characters',
    'runtime_minutes', 'types'
]

df_Film_Att = df[Film_Attributes]
df_Film_Att.head()


df_Film_Att.info()


# No of title ids
print(len(df.title_id))
# No of titles
print(len(df.title))

len(df.title_id) - len(df.title)


# No of Unique `title` along the `title` column
print(len(df_Film_Att['title'].unique()), end = '\n\n')

# No of Unique `original_title` along the `original_title` column
print(len(df_Film_Att['original_title_fr8'].unique()), end = '\n\n')

# Check how many title are similar
print((df_Film_Att['title'] == df_Film_Att['original_title_fr8']).sum())

# No of unique values
unique_title = len(df_Film_Att['title'].unique())
unique_original_title = len(df_Film_Att['original_title_fr8'].unique())
unique_original_title_fr134567 = len(df_Film_Att['original_title_fr134567'].unique())

# Print the above info
print(f'The number of unique `title` in the dataset, {unique_title}')
print('The number of unique `original_title_fr134567` in the dataset, {unique_original_title_fr134567}')
print(f"The number of unique `original_title` in the dataset, {unique_original_title}, end = '\n\n'")

# PieChart
y = np.array([unique_title, unique_original_title, unique_original_title_fr134567])
mylabels = ["unique_title", "unique_original_title", 'unique_original_title_fr134567']

# Plot size
plt.figure(figsize = (6, 8))

# Plot Title
plt.title("UNIQUE TITLES IN DATAFRAME")

# plot parameters
myexplode = [.1, 0.1, 0.1]
mycolors = ['red', 'green', 'violet']

# The Plot
plt.pie(y, labels = mylabels, startangle = 90, 
        explode = myexplode, shadow = False, 
        colors = mycolors)

# Plot Legend
plt.legend(title = 'No of `title`, `original_title` and `unique_original_title_fr134567`', loc ="lower left")
plt.show()





# Stripped of columns
Film_Attributes = [
    'title_id', 'studio', 'language', 
    'is_original_title', 'attributes', 
    'genres', 'genre_ids', 'characters',
    'runtime_minutes', 'types'
]

df_Film_Att = df_Film_Att[Film_Attributes]
df_Film_Att.head(3)


# types columns
df_Film_Att.types.unique()


df_Film_Att.attributes.unique()[:10]


df_Film_Att.characters.unique()





# final strip of columns
Film_Attributes = [
    'title_id', 'studio', 'language', 
    'is_original_title', 'attributes', 
    'genres', 'genre_ids', 'runtime_minutes'
]

df_Film_Att = df_Film_Att[Film_Attributes]
df_Film_Att.head(3)





Timelines_and_Region = [
    'year', 'start_year', 'region', 'original_language', 
    'release_date_fr1345678', 'release_date_fr9'
]

time_and_Reg_Df = df[Timelines_and_Region]
time_and_Reg_Df.head()





final_time_and_region = [
    'year', 'start_year', 'region', 
    'original_language', 'release_date_fr1345678'
]





Professionals = [
    'primary_name', 'birth_year', 'death_year', 'category',
    'primary_profession', 'known_for_titles',
    'directors', 'writers', 'tconst', 'nconst', 'job'
]

prof_df = df[Professionals]
prof_df.head()





Financials = ['production_budget', 'domestic_gross_fr1345678', 
    'domestic_gross_fr9', 'foreign_gross', 'worldwide_gross']


fin_df = df[Financials]
fin_df.head()





fin_financials = [
    'production_budget',  'domestic_gross_fr9', 
    'foreign_gross', 'worldwide_gross'
]


# (v) Popularity Scores
Popularity_scores = [
    'vote_average', 'vote_count',
    'popularity'
]

Pop_score_df = df[Popularity_scores]
Pop_score_df.head()


fin_cols = [
    # financial attributes
    'title_id', 'studio', 'language', 
    'is_original_title', 
    'genres', 'genre_ids', 'runtime_minutes',
    
    # timelines and financials
    'year', 'start_year', 'region', 
    'original_language', 'release_date_fr1345678',
    
    # professionals
    'primary_name', 'birth_year', 'death_year', 'category',
    'primary_profession', 'known_for_titles',
    'directors', 'writers', 'tconst', 'nconst', 'job',
    
    # Financials
    'production_budget',  'domestic_gross_fr9', 
    'foreign_gross', 'worldwide_gross',

    # Popularity Scores
    'vote_average', 'vote_count',
    'popularity'
]





df = df[fin_cols]
df.head()


df.info()





# Checking the unique elements in the 
# `is_original_title`
df.is_original_title.unique()





# convert the dtype
df.is_original_title.replace({0.0: 'No', 1.0: 'Yes', np.nan:'Unknown'}, inplace = True)

# Print the dtype of the column
df.is_original_title.dtype == 'O'


# print of each category in the 
# is_original_title
print(df.is_original_title.value_counts())

# Count of each category in the Original titles
Original_title = ((df.is_original_title == 'Yes').sum())
None_Original_title = ((df.is_original_title == 'No').sum())
Unknown_Original_title = ((df.is_original_title == 'Unknown').sum())

print(Original_title, None_Original_title, Unknown_Original_title)


# Print the above info
print(f'The number of unique `Original_title` in the dataset, {Original_title}')
print(f'The number of unique `None_original_title` in the dataset, {Unknown_Original_title}')
print(f"The number of unique `Unknown_Original_title` in the dataset, {Unknown_Original_title}'"
     , end = '\n\n')


# PieChart
y = np.array((Original_title, None_Original_title, Unknown_Original_title))
mylabels = ["Original_Title", "None_Original_title", 'Unknown_Original_title']

# Plot size
plt.figure(figsize = (6, 8))

# Plot Title
plt.title("THE ORIGINAL TITLES IN THE DATASETS")

# plot parameters
myexplode = [0.0, 0.1, 0.3]
mycolors = ['green', 'red', 'blue']

# The Plot
plt.pie(y, labels = mylabels, startangle = 45, 
        explode = myexplode, shadow = False, 
        colors = mycolors)

# Plot Legend
plt.legend(title = 
           'No of `Original_Title`, `None_Original_title` and `Unknown_Original_title`', 
           loc ="lower left")

plt.show()


df.head(2)


# Check how many null values are present
# in `runtime_minutes` column

# null_values_in_runtime
null_values_in_runtime = df.runtime_minutes.isnull().sum()
# non_null_values_in_runtime
non_null_values_in_runtime = df.runtime_minutes.notna().sum()

# Perc
total = df.shape[0]
# perc_null_values_in_runtime
perc_null_values_in_runtime = null_values_in_runtime / total * 100
# perc_non_null_values_in_runtime
perc_non_null_values_in_runtime = non_null_values_in_runtime / total * 100


# Print these values
print(f'Null values are {perc_non_null_values_in_runtime} %', 
      f'Non-Null values are {perc_null_values_in_runtime} %', 
      sep = '\n')

# Print how many they are
print(f'{null_values_in_runtime, 2}',
      f'{null_values_in_runtime}',
      f'{non_null_values_in_runtime}', 
      sep = '\n')


# PieChart
# For `runtime_minutes`
y = np.array([perc_null_values_in_runtime, 
              perc_non_null_values_in_runtime
             ])

mylabels = ["Percentage of Null Values", 
            "Percentage of Non-Null Values"]

# Plot size
plt.figure(figsize = (6, 8))

# Plot Title
plt.title("Percentage of Null Values in dataset")

# plot parameters
myexplode = [.1, 0.1]
mycolors = ['blue', 'green']

# The Plot
plt.pie(y, labels = mylabels, startangle = -45, 
        explode = myexplode, shadow = False, 
        colors = mycolors)

# Plot Legend
plt.legend(title = 
           'PERCENTAGE OF NULL VALUES IN DATASET.', 
           loc ="lower left")

plt.show()


# Dropping null values in `runtime_mninutes`
df.dropna(subset = ['runtime_minutes'], inplace = True)


# Executable 3

print(df.runtime_minutes.dtype) 
df.runtime_minutes = df.runtime_minutes.astype('int64')


df.runtime_minutes.dtype


df.head(3)


df.info()


# Start_year and `year`


nul_vals_in_strt_yr = df.start_year.isnull().sum()
nul_vals_in_yr = df.year.isnull().sum()

print(f'There are {nul_vals_in_strt_yr} values in `start_year`.', 
      f'There are {nul_vals_in_yr} values in `year`.',
      sep = '\n')





df.info()





# Checking the data type of the `runtime_minutes`
print(df.runtime_minutes.dtype)

# No of nulls in language col
no_of_nul_in_lang = df.language.isnull().sum()
# No of nulls in original col
no_of_nul_in_org_lang = df.original_language.isnull().sum()

# Perc
perc_no_of_nul_in_lang = no_of_nul_in_lang / total * 100
perc_no_of_nul_in_org_lang = no_of_nul_in_org_lang / total * 100

# Print the results
print(f"""There are {no_of_nul_in_lang} null values in `language` the dataset. 
i.e. {round(perc_no_of_nul_in_lang,2)} %""",
      f"""There are {no_of_nul_in_org_lang} null values in the `original_language` dataset. 
i.e. {round(perc_no_of_nul_in_org_lang, 2)} %""",
     sep = '\n')





# Initially Check the null values in original values
df.original_language.unique()

# Change the `nan` to `unknown`
df.original_language.replace({np.nan:'Unknown'}, inplace = True)


# The `job` column doesn't play any significant role in the dataset
df.job.isnull().sum() / total * 100


# Check the unique values in the column 
# in the `category`
df.category.unique()





# checking the primary name column
df.primary_name.unique()
len(df.primary_name.unique())





# Checking what constitutes this column
# df.tconst

# Checking whether there is a similar relationship 
# betweenn these 2 columns
df.directors[0] == df.nconst[0]

# Printing to check to see whether there is something
# Similar in these columns
# print(df.directors[:5], df.nconst[:5], df.writers[:5])


# Renaming the `release_date_fr1345678` to `release_date`
df.rename(columns = {'release_date_fr1345678': 'release_date'}, inplace = True)

# Renaming the `domestic_gross_fr9` to `domestic_gross`
df.rename(columns = {'domestic_gross_fr9': 'domestic_gross'}, inplace = True)


# Converting the datatype of `start_year` 
# from `float64` to `int64`
df.start_year = df.start_year.astype('int64')

# Feedback
print('Done!')


# Converting `production_budget`
df.production_budget = df.production_budget.replace('[\$,]', '',
                                                    regex = True).astype(float)

# Converting `foreign_gross`
df.domestic_gross  = df.domestic_gross.replace('[\$,]', '', 
                                             regex = True).astype(float)

# Converting `foreign_gross`
df.worldwide_gross = df.worldwide_gross.replace('[\$,]', '', 
                                             regex = True).astype(float)

print('Done!')


df.release_date.unique().tolist()

# 'nan' in df.release_date
np.nan in df.release_date

# Empty rows in the `release_date` column
empt_rel_date = df.release_date.isnull().sum()

# none empty rows in the `release_date` column
non_empt_rel_date = df.release_date.notna().sum()

# print(results)
print(f"There are {empt_rel_date} empty rows in the `release_date` column.",
      f"There are also {non_empt_rel_date} none-empty row in the same column.",
      "\nA similar value. It then makes sense to drop the empty columns.",
      sep = '\n')


lisT = df.start_year.loc[df.release_date.isnull()].unique().tolist()#.sort_values()
sorted(lisT)
len(lisT)

# Dropping the empty rows in the column
df.dropna(subset = ['release_date'], inplace = True)

# Checking whether there are still
# empty rows in the `release` column
df.release_date.isnull().sum()


# converting the datatype of the `release_year` 
# from 'String Object' to 'datetime'
df.release_date = pd.to_datetime(df.release_date)

# Checking the dataType of entries 
# in the `release_date` col
df.release_date.dtype


df.info()





final_cols = [
    # financial attributes
    'title_id', 'studio', 'original_language',
    'is_original_title', 'runtime_minutes',
    
    # timelines and financials
    'release_date', 'start_year', 'region', 'genres', 'genre_ids', 
    
    # professionals
    'nconst', 'known_for_titles',
    
    # Popularity Scores
    'vote_average', 'vote_count',
    'popularity', 
    
    # Financials
    'production_budget', 'domestic_gross', 'worldwide_gross'
]

len(final_cols)


df = df[final_cols]
df.head()


final_cols = [
    # financial attributes
    'title_id', 'original_language',
    'is_original_title', 'runtime_minutes',
    
    # timelines and financials
    'release_date', 'start_year', 'studio', 'region', 'genres', 'genre_ids', 
    
    # professionals
    'nconst', 'known_for_titles',
    
    # Popularity Scores
    'vote_average', 'vote_count',
    'popularity', 
    
    # Financials
    'production_budget', 'domestic_gross', 'worldwide_gross'
]

df = df[final_cols]
df.head(3)


df.info()





# # Export the DataFrame
# df.to_csv('finalDataframe.csv') 
# # Note, file size is 68mbs; necesitating the zipping.

# # Feedback
# print('Done')





df.head(3)


df.info()


df.describe()











# Before Cleaning
no_of_film_b4_clean = len(df_1to9.title.unique())
print(f'There was {no_of_film_b4_clean} films before EDA.', end = '\n')

# After DATA Cleaning
no_of_film_after_clean = len(df.title_id.unique())
print(f'There was {no_of_film_after_clean} films before EDA')


# This represents 
round(no_of_film_after_clean / no_of_film_b4_clean * 100, 2)


year_title_frame = df.groupby('start_year').title_id.agg(len).to_frame()
year_title_frame = year_title_frame.reset_index()

# Timeline valiables
year_fr = list(year_title_frame['start_year'])
year_title_fr = list(year_title_frame['title_id'])

plt.figure(figsize = (8,5))
plt.title('A BarGraph Showing the Number of Titles Produced per Year.')
plt.bar(year_fr, year_title_fr)
plt.xlabel('Year of Production')
plt.ylabel('Number of Films')
plt.show()


sns.lineplot(data = year_title_fr)
plt.show()





year_timeline = sorted(df.start_year.unique())
year_timeline


# oldest year in Dataset
oldest_year = df.start_year.min()
print(f'The oldest year in the dataset is {oldest_year}.')

# latest year
latest_year = df.start_year.max()
print(f'The latest year in the dataset is {latest_year}.')





# Checking which rows have a release date below 2010
below_2010 = len(df.loc[df.release_date <= '2010-01-01'].sort_values(by = 'release_date', 
                                                    ascending = True))#[1500:1515]

# how many `release_dates`
all_years = len(df.release_date)

# perc of rows below 2010
below_2010 / all_years * 100


df.groupby(['start_year']).start_year.agg(len)
bar_data = df.groupby(['start_year']).start_year.agg(len)

bar_df = pd.DataFrame(bar_data)
X_Vals = list(bar_df.index)
Y_Vals = list(bar_df.start_year)

print(X_Vals, Y_Vals, sep = '\n\n')


# Plot Size
plt.figure(figsize=(8,5))

# Plot Title
plt.title('Number of Films Each Year Within Timeline.')

# sns.lineplot(data = spotify_data)
plt.plot(X_Vals, Y_Vals, color = 'b', linewidth = '1.5')

# Labels
plt.xlabel("Year Number")
plt.ylabel("Number of Appearance")

# Plot Show
plt.show()





# Seeking the unique language elements in data
lang_list = df.original_language.unique()#.tolist()

# The langauges present in the dataset
# print(lang_list, end = '\n\n')

# number of languages in the dataset
len_lang_list = len(lang_list)

# Print results
print(f"There are {len_lang_list} Film langueges in the Cleaned Dataset.",
     f"These includes, but not limited to, {lang_list[:10]}.", sep = '\n\n',
     end = '\n\n')


# Top performing languages domestically
lang_dom_perf = df.groupby(['original_language']).domestic_gross.agg([len, max])
lang_dom_perf = lang_dom_perf.reset_index()
lang_dom_perf = lang_dom_perf.sort_values(by = 'max', ascending = False)[:10]
lang_dom_perf.set_index('original_language', inplace = True)
lang_dom_perf = lang_dom_perf.rename(columns = {'max': 'domestic_gross', 'len': 'no_of_appearance'})
lang_dom_perf

# Line chart showing the Top 10 higest languages in terms of Domestic revenue
plt.figure(figsize = (8,5))
plt.title('Top 10 Highest Languages In Terms Of Domestic Revenue')
plt.plot(lang_dom_perf.domestic_gross)
plt.xlabel('Original Language')
plt.ylabel('Domestic Revenue')
plt.show()


# Top performing languages worldwide
lang_wor_perf = df.groupby(['original_language']).worldwide_gross.agg([len, max])
lang_wor_perf = lang_wor_perf.reset_index()
lang_wor_perf = lang_wor_perf.sort_values(by = 'max', ascending = False)[:10]
lang_wor_perf.set_index('original_language', inplace = True)
lang_wor_perf = lang_wor_perf.rename(columns = {'max': 'worldwide_gross', 'len': 'no_of_appearance'})
lang_wor_perf

# Line chart showing the Top 10 higest languages in terms of Domestic revenue
plt.figure(figsize = (8,5))
plt.title('Top 10 Highest Languages In Terms Of Worldwide Revenue')
plt.plot(lang_wor_perf.worldwide_gross)
plt.xlabel('Original Language')
plt.ylabel('Worldwide Revenue')
plt.show()





# Investigating original titles
originals_titles = (df.is_original_title == 'Yes').sum()
non_originals_titles = (df.is_original_title == 'No').sum()
Unknwn_originals_titles = (df.is_original_title == 'unknown').sum()

print(f'The Number of Original Films are {originals_titles}.', 
      f'There are {non_originals_titles} remake films.', 
      f'There are {Unknwn_originals_titles} unknown films.', 
      sep = '\n')


# PieChart
y = np.array((originals_titles, non_originals_titles, Unknwn_originals_titles))
mylabels = ["Original_TitleS", "non_originals_titles", 'Unknown_Original_titles']

# Plot size
plt.figure(figsize = (6, 8))

# Plot Title
plt.title("THE ORIGINAL TITLES IN THE CLEANED DATA")

# plot parameters
myexplode = [0.0, 0.1, 0.3]
mycolors = ['gray', 'blue', 'red']

# The Plot
plt.pie(y, labels = mylabels, startangle = 145, 
        explode = myexplode, shadow = False, 
        colors = mycolors)

# Plot Legend
plt.legend(title = 
           'No of `Original_Title`, `non_originals_titles` and `Unknown_Original_titleS`', 
           loc ="lower left")

# Plot Show
plt.show()


orig_title_perf = df[['is_original_title', 'domestic_gross', 'worldwide_gross']]
# orig_title_perf.sort_values(by = 'worldwide_gross', ascending = True)
orig_title_perf = orig_title_perf.sort_values(by = 'worldwide_gross', ascending = False)
orig_title_perf = orig_title_perf[:1000]

# plot size
plt.figure(figsize = (8, 5))

# plot title
plt.title("Performance of the `Original_title` in Worldwide Markets.")

# The Plot
sns.swarmplot(x = orig_title_perf['is_original_title'],
              y = orig_title_perf['worldwide_gross'])

plt.show()


# Determining which genre is represented by '[10402, 18, 10749]'
df.genres.loc[(df.genre_ids == '[10402, 18, 10749]')].iloc[0]





df.runtime_minutes.describe().to_frame()


# Choosing the runtime cols
runtime_boxplot = pd.DataFrame(df.runtime_minutes)

# The Average runtime of films is:
Avg_runtime = runtime_boxplot.mean() # 94.491577

# print(Results)
print(f"The Average runtime of the film is {Avg_runtime}.")

# Size Figure
plt.figure(figsize = (6, 2))

# Plot Title
plt.title('A BOXPLOT OF THE `runtime_minutes` IN DATA')

# Plot
plt.boxplot(runtime_boxplot, showfliers = False, notch=False, vert=False)

# Show
plt.show()





# No of rows in the Cleaned Rows
total = df.shape[0]

# Print(No of rows)
print(total)


# no of Unknown Studios
no_of_unknown_studios = df.studio.isnull().sum()

# the `known` studios 
unique_known_studios = df.studio.loc[df.studio.notna()].unique()

# no of unknown studios?
print(f"There are {no_of_unknown_studios} Unknown Studios.", 
      end = '\n\n')

# no of unique studio?
print(f"There are {unique_known_studios[:15]}, and more, Uniquely known Studios.", 
      end = '\n\n')

# perc of known studios
len(df.studio.loc[df.studio.notna()].tolist()) / len(df.studio) * 100


df.groupby(['studio', 'domestic_gross']).worldwide_gross.agg(max).to_frame().sort_values(by = 'worldwide_gross', ascending = False)


# Top 10 performing Studios Domestically
Top_10_performing_Studios_Domestically = df.groupby(['studio']).domestic_gross.agg(max).to_frame().sort_values(by = 'domestic_gross', ascending = False)[:10]
Top_10_performing_Studios_Domestically = Top_10_performing_Studios_Domestically.reset_index()
Top_10_performing_Studios_Domestically

# valuables
x_Top_10_performing_Studios_Domestically_studio = Top_10_performing_Studios_Domestically.studio
y_Top_10_performing_Studios_Domestically_worldwide = Top_10_performing_Studios_Domestically.domestic_gross

# The Plot
plt.figure(figsize=(8,5))
plt.title('Top 10 Performing Studios in Terms of Domestic Markets.')
plt.barh(x_Top_10_performing_Studios_Domestically_studio, y_Top_10_performing_Studios_Domestically_worldwide)
plt.xlabel('Domestic_gross Revenues')
plt.ylabel('Name of Studio')
plt.show()


# Top 10 performing Studios Worldwide
Top_10_performing_Studios_Worldwide = df.groupby(['studio']).worldwide_gross.agg(max).to_frame().sort_values(by = 'worldwide_gross', ascending = False)[:10]
Top_10_performing_Studios_Worldwide = Top_10_performing_Studios_Worldwide.reset_index()
Top_10_performing_Studios_Worldwide

# valuables
x_Top_10_performing_Studios_Worldwide_studio = Top_10_performing_Studios_Worldwide.studio
y_Top_10_performing_Studios_worldwide_gross = Top_10_performing_Studios_Worldwide.worldwide_gross

# The Plot
plt.figure(figsize=(8,5))
plt.title('Top 10 Performing Studios in Terms of Worldwide Markets.')
plt.barh(x_Top_10_performing_Studios_Worldwide_studio, y_Top_10_performing_Studios_worldwide_gross)
plt.xlabel('Worldwide_gross Revenues')
plt.ylabel('Name of Studio')
plt.show()


# Studios in regions
stud_reg_df = df.groupby(['region']).studio.agg(len).to_frame()
stud_reg_df = stud_reg_df.reset_index()

# Top most Regions with the most Studio
stud_reg_df = stud_reg_df.sort_values(by = 'studio', ascending = False)[:10]
stud_reg_df

x_va = list(stud_reg_df.region)
y_va = list(stud_reg_df.studio)

plt.figure(figsize = (8,6))
plt.title('Top Most Preferred Region for Studios.')
plt.bar(x_va, y_va)
plt.xlabel('Regions')
plt.ylabel('Number of Studios')
plt.show()





df.genre_ids.unique()


# Top 10 most frequent genres
gen_df = df.groupby(['genre_ids', 'domestic_gross']).worldwide_gross.agg(max).to_frame()
gen_df.head(10)
gen_df = gen_df.reset_index()
gen_df = gen_df[:10]
gen_df = gen_df.set_index('genre_ids')
gen_df


# Values
# y_gen_values = list(gen_df.genre_ids)
# x_gen_values = gen_df.genres.tolist()

# Plot size
plt.figure(figsize = (8,5))

# Plot Title
plt.title('Performance of the Top 10 Genres in Domestic and Worldwide Markets.')

# The Plot
# plt.barh(x_gen_values, y_gen_values, color = "green")
my_plot = sns.lineplot(data = gen_df)
my_plot.set_xticklabels(my_plot.get_xticklabels(), rotation=45)

# labels
plt.xlabel('Genres')
plt.ylabel('Kind of Genre')

# Show the Plot
plt.show()





# No of Regions in Data
df.region.nunique()


# Top 10 regions
reg_val_counts = df.region.value_counts().to_frame()[:10]
reg_val_counts = reg_val_counts.reset_index()
reg_val_counts = reg_val_counts.set_index('region')
reg_val_counts


# Top 10 Performing Regions Domestically
top_10_perf_reg_dom = df.groupby('region').domestic_gross.agg(max).to_frame().sort_values(by = 'domestic_gross', ascending = False)[:10]
top_10_perf_reg_dom = top_10_perf_reg_dom.reset_index()
top_10_perf_reg_dom

# values
x_value_dom = list(top_10_perf_reg_dom.region)
y_value_dom = list(top_10_perf_reg_dom.domestic_gross)

# The plot
plt.figure(figsize = (8, 5))
plt.title('The Top 10 Performing Regions Domestically.')
plt.bar(x_value_dom, y_value_dom, color = 'indigo')
plt.xlabel('Name of Region')
plt.ylabel('Domestic Revenue Performance')
plt.show()


# Top 10 Performing Regions Worldwide
top_10_perf_reg_wor = df.groupby('region').worldwide_gross.agg(max).to_frame().sort_values(by = 'worldwide_gross', ascending = False)[:10]
top_10_perf_reg_wor = top_10_perf_reg_wor.reset_index()
top_10_perf_reg_wor

# values
x_value_wor= list(top_10_perf_reg_wor.region)
y_value_wor = list(top_10_perf_reg_wor.worldwide_gross)

# The plot
plt.figure(figsize = (8, 5))
plt.title('The Top 10 Performing Regions in Worldwide.')
plt.bar(x_value_wor, y_value_wor, color = 'g')
plt.xlabel('Name of Region')
plt.ylabel('Worldwide Revenue Performance')
plt.show()


reg_df = df.groupby(['region', 'domestic_gross']).worldwide_gross.agg(max).to_frame().sort_values(by = 'domestic_gross', ascending = False)
reg_df = reg_df.reset_index()
reg_df = reg_df.set_index('region')
reg_df = reg_df[:10]
reg_df


# Plot size
plt.figure(figsize = (8, 5))

# Plot Title
plt.title('Performance of the Top 10 regions in Domestic and Worldwide Markets.')

# The Plot
# plt.barh(x_gen_values, y_gen_values, color = "green")
My_plot = sns.lineplot(data = reg_df)
My_plot.set_xticklabels(My_plot.get_xticklabels(), rotation=45)

# labels
plt.xlabel('Various Regions')
plt.ylabel('Financial Performance')

# Show the Plot
plt.show()





df.original_language.unique()


# Choice of columns
lang_df_perf = df[['original_language', 'domestic_gross', 'worldwide_gross']]

# Groupby Frame
lang_df_perf = lang_df_perf.groupby(['original_language']).worldwide_gross.agg(max).to_frame().sort_values(by = 'worldwide_gross', ascending = False)[:10]
lang_df_perf = lang_df_perf.reset_index()
lang_df_perf = lang_df_perf.set_index('original_language')


# plot size
plt.figure(figsize = (10,5))
# Plot Title
plt.title('Performance of the Top 10 Languages')
# The Plot
sns.histplot(x = lang_df_perf.index, y = lang_df_perf.worldwide_gross)



